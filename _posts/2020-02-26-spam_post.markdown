---
layout: post
title:  "Spam Detector"
permalink: /spam_ham/
date:   2019-02-01 12:33
image: ../assets/images/spam.png
categories: jekyll update
---

<a href="https://github.com/GaelGil/algorithms/blob/master/data_stuff/spam_analysis/data_eval.ipynb"> Link to the Jupyter Notebook where I show my work</a>


In this blog post I will be talking about creating a spam detector. I did not use any libraries but I know they exist and make things easier and I will be talking about in the blog post as well. 


I got the data from the UC Irvine Machine Learning Repository


### What I'll be talking about
My thought proccess<br>
Thinking about the problem<br>
Trying my first algorithm<br>
Analsying the issue<br>
Solution to the previous issue<br>
Results<br>
Solving this issue using sklearn<br>



### What the issue is
How do we classfiy a message as spam or ham(not spam)


### Things to know
Supervised Machine Learning<br>
Classification <br>
Jupyter NoteBooks<br>
What is ham<br>
How dictionaries work


### Attempt 1 
My first algorithm was a very simple. The idea was that my algorithm would take a in a message which would then be made into a dictionary containing the words of the message as it's keys. Once we had the dictionary we needed to store the spam and ham values of that word so we put a dictionary of values for the words set to 0. This would allow us to track the spam and ham values of each word and check if a message has a lot of spam words or not. For example if the word `free` appeared in the message it would have a larger spam value than a ham value so it would get marked as `spam: 1` and `ham: 0`. Here is a sample run of what it would look like using the sentence `the sky is blue`.
Here is our dictionary with our words and keys. 

~~~python

words_dict = {
    'the': ['spam']: 0, ['ham'] : 0,
    'sky': ['spam']: 0, ['ham'] : 0,
    'is': ['spam']: 0, ['ham'] : 0,
    'blue': ['spam']: 0, ['ham'] : 0,
}

~~~

Since we now have our dictionary the next step is to look up our words in another dictionary that contains words and probabilities of them being spam or not already filled in. This will allow us to compare our message to see what our words probabilities of being spam or ham.


~~~python

# Our dict
words_dict = {
    'the': ['spam']: 0, ['ham'] : 0,
    'sky': ['spam']: 0, ['ham'] : 0,
    'is': ['spam']: 0, ['ham'] : 0,
    'blue': ['spam']: 0, ['ham'] : 0,
}

# The dictionary we look up our words in
prefilled_dict = {
    'the': ['spam']: 7, ['ham'] : 10,
    'sky': ['spam']: 0, ['ham'] : 12,
    'is': ['spam']: 6, ['ham'] : 10,
    'blue': ['spam']: 0, ['ham'] : 15,
    'free': ['spam']: 15, ['ham']: 4,
    'cat': ['spam']: 0, ['ham']: 12,
    'exclusive': ['spam']: 16, ['ham']: 3,
}

~~~

Once we have compared our words our dictionary would have the values for each word and would look like this.

~~~python

words_dict = {
    'the': ['spam']: 7, ['ham'] : 10,
    'sky': ['spam']: 0, ['ham'] : 12,
    'is': ['spam']: 6, ['ham'] : 10,
    'blue': ['spam']: 0, ['ham'] : 15,

~~~

Now that we have the values for the words we can check which value is higher. In another function I passed in our dictionary where we would do this. The function would check if the spam value was higher than the ham value, if it was we would add 1 to the list and if not we add 0.So we have list with ones and zeroes. If the list had more 1s than zeroes it was spam. Our current example would look like this

~~~python

words_nums = [0, 0, 0, 0]

~~~


This algorithm did really bad on the training data I don't really remeber the scores it got but I know it was really low that I didn't bother using the test data. One of the main issues I had was not having words to compare it to which meant almost everything was set to ham. As I said earlier this algorithm looked at everyword in the message and looked it up in a dictionary with prefilled words and values but that algorithm only had only maybe 10 or so words already manually set by me. This wouldn't have been such a bad idea if I had lots and lots of words but the issue with this is I would not know what to set their spam and ham values to. So with this came the idea for my next algorithm. 

### Attempt 2 
After looking into possibilites of solving my issue with my first algorithm I had my new idea. The idea was that first we would set all the data (words) into dictionary form, where every word in the dataset would have its spam and ham value. This new algorithm would go through every messsage and clean the message (which I had not done previosly) by removing punctuationa and making every word lowercase. Doing this is good for many reasons one of them being. Once we have our clean message in a list form we can now input the words it into the dictonary with their values (default to 1). 

~~~python

#####This function is for setting the words into the probability dictionary   
def add_words_to_dict(sms_list:list):
    """
    This function takes in a list as its argument and with
    the items of those list we create a dictonary with the
    words as keys. 
    """
    for i in range(len(sms_list)):
        # select current word
        word = sms_list[i]

        # if word is already there ignore it for now
        if word in PROBS:
            pass

        elif word not in PROBS:
            # if word is not in there set their ham and spam values to 1
            PROBS[word] = {'spam' : int(1), 'ham' : int(1)}

~~~


They way in which I assigned the values to a word was by its label (this is supervised machine learning so we have the labels for each message). The algorithm had a function which would take its label as its argument and the message its self. Depending on the label it would I would add a point to its label. If that is confusing here is the function.


~~~python

##### This function is for assigning spam and ham values to words  
def assign_vals_to_words(label:str, sms_list:list):
    """
    This function takes in a string (label of sms) and the sms 
    as a list. Depending on the label we will add 1 to every 
    word on that list label value.
    """
    spam = 'spam'
    ham = 'ham'
    if label == spam:
        # for all spam sms in our train data sets
        for i in range(len(sms_list)):
            # select word
            word = sms_list[i]
            # add 1 to their spam values
            PROBS[word][spam] += 1
    elif label == ham:
        # for all ham sms in our train data sets
        for i in range(len(sms_list)):
            # select word
            word = sms_list[i]
            # add 1 to their ham values
            PROBS[word][ham] += 1       
    else:
        pass


~~~


What the function is doing is 
After the first iteration if a word was already in the dictionary we would just add to its spam or ham value depending on its label.

Heres a sample of what the dictionary looked like 

~~~python



~~~


 Now that we have a dictionary of probabilities we can now try everything again


### changes to algorithms
Every algorithm follewd the same proccess as the first one. We sould set the data into dictionary form, count up words and their probabilities and see what we could do with that after.

Used naive byes after worked better but overfitted
A very common way to solve this was by using naive byes. 



I went online and did some more resaerch to see what other things people did. One of the things that I noticed was people removed stop words. I dont neccisarily know by definitiin what stop words are but from my understanding they are very common word such as `the`, `is`, `they`, etc. So for my next idea to try and improve my algorithms accuracy I removed the stop words. The proccess of the remvoing the stop words was done a long with cleaning the message. Here is the function that removed the stop words.

~~~python
~~~

In the end this really had no effect and gave me the same results my previous algorithm


Graphed the word probabilites to see if it could show something (final algorithm)
Using sklearn




### Testing Accuracy
I created a function called `test_accuracy` this would take in another function (the algorithm) as its arugment and some data (training data)
Every algorithm version I tested I imported into the the jupyter notebook and passed in through the `test_accuracy` along with the trainng data. What test acurracy did

~~~python


def get_accuracy(algorithm, data):
    # ammount correct for each label
    correct_ham = 0
    correct_spam = 0
    correct = 0
    
    # the occurances of each label in the data set
    spam = len(data.groupby(['true_category']).get_group('spam'))
    ham = len(data.groupby(['true_category']).get_group('ham'))
    
    # lenght of the dataset
    len_of_data = len(data)

    for i in range(len(data)):
        # get the message and label 
        sms = data['message'][i]
        label = data['true_category'][i]
        
        # call function
        prediction = algorithm(sms) # this returns "spam" or "ham"
        
        if prediction == label:
            # If prediction is correct we add 1 overall correct
            correct += 1
            if prediction == 'spam':
                # If the predicted label is spam and acutal label
                # is spam then we add to amount correct for spam
                correct_spam +=1
            elif prediction =='ham':
                # If the predicted label is ham and acutal label
                # is spam then we add to amount correct for ham
                correct_ham +=1
    
    print((correct_ham+correct_spam)/2)
    print('Correct Ham: ', + correct_ham/ham)
    print('Correct Spam: ', + correct_spam/spam)
    print('Correct: ', + correct/len_of_data)

~~~

<!-- ### steps -->
<!-- ### analyzing data  -->
<!-- ### discoveries -->
### challenges
### what i learned
### future improvements
Not a improvement but while doing research I found out that this same algorithm could possibly work with classifing wether a sentence is positive or negative like if what someone is saying is good or bad.